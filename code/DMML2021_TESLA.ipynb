{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgvspMaF7sI6"
      },
      "source": [
        "WELCOME TO THE COLAB NOTEBOOK OF UNIL_TESLA GROUP!\n",
        "\n",
        "\n",
        "Steps:\n",
        "\n",
        "\n",
        "1) Take the training set, split it 80-20, train models on the train set and test it on the test set. But, then, when we train the model to submit on kaggle we can use all the dataset to train,\n",
        "\n",
        "2) Calculate the baseline and all 4 precisions (of 4 models), then vary the parameters to optimize i\n",
        "\n",
        "3) Then, use a model (or combinaison of many) after doing some data cleaning (e.g. removing stop words, lemmatization, tokenization, etc...) and compute the precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXf_1RtRtDBC"
      },
      "source": [
        "## 1. Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "hZvB3DyD3gMc",
        "outputId": "800ff7b9-f29f-437c-b41a-79d8a7291f83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Collecting fr-core-news-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.2.0/fr_core_news_sm-3.2.0-py3-none-any.whl (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 296 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from fr-core-news-sm==3.2.0) (3.2.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.8.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "# Import required packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string # to get punctuations = string.punctuation\n",
        "\n",
        "from numpy.ma.core import append\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "!pip install -U spacy\n",
        "!python3 -m spacy download fr_core_news_sm\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FYvd6-6VmXn"
      },
      "source": [
        "## 2. Define and split the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "1Qnb-9GXZucW"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('https://raw.githubusercontent.com/Broly-brolik/DMML2021_Tesla/main/data/unlabelled_test_data.csv')\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/Broly-brolik/DMML2021_Tesla/main/data/training_data.csv')\n",
        "sample_submission = ('https://raw.githubusercontent.com/Broly-brolik/DMML2021_Tesla/main/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "sa6ubLw4Vs1q"
      },
      "outputs": [],
      "source": [
        "np.random.seed = 0\n",
        "X = train_data['sentence'] # 'sentence' is the feature to have as in input\n",
        "y = train_data['difficulty'] # 'difficulty' is our target, the output.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWxkGB_NWSNL"
      },
      "source": [
        "## 3. Train our models & make predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.0. Important functions"
      ],
      "metadata": {
        "id": "iOJiml3qp8bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a function that will evaluate each of our different models we'll create\n",
        "def evaluate(true, pred):\n",
        "      precision = precision_score(true, pred, pos_label='positive', average='macro')\n",
        "      recall = recall_score(true, pred, pos_label='positive', average='macro')\n",
        "      f1 = f1_score(true, pred, pos_label='positive', average='macro')\n",
        "      print(f\"CONFUSION MATRIX:\\n{confusion_matrix(true, pred)}\")\n",
        "      print(f\"ACCURACY SCORE:\\n{accuracy_score(true, pred):.4f}\")\n",
        "      print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")\n",
        "\n",
        "# Create tokenizer function for LR\n",
        "def spacy_tokenizer(text):\n",
        "  mytokens = sp(text)\n",
        "  return mytokens"
      ],
      "metadata": {
        "id": "ksQt85B-p2sO"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugZXoINUXZAh"
      },
      "source": [
        "### 3.1. Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "GfpH7xFLaS7o",
        "outputId": "5ce7f923-f0c1-4c92-d504-20ec8d1bb5fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1694"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "# Compute the baseline : 0.1694\n",
        "# We calculate the most frequent item in y and divide it by the total number of observations.\n",
        "# We round it to 4 digits and take the maximum.\n",
        "# Let stock it in baseline variable.\n",
        "baseline = max(round(y.value_counts()/len(train_data), 4))\n",
        "baseline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: It is equivalent to do it like that (and can you guess why? :)):\n",
        "round(max(y.value_counts())/len(train_data), 4)\n",
        "# If you don't see the difference, we just switched max<->round"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeIpKJC9otvm",
        "outputId": "9c603f6b-e9d1-452d-a60c-04ac6db2b31d"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1694"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwFXBwdbk-ri"
      },
      "source": [
        "### 3.2. Logistic regression (without data cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "KeI6cgVN3m9y"
      },
      "outputs": [],
      "source": [
        "# Instanciation of the tool\n",
        "# Loading french language\n",
        "sp = spacy.load(\"fr_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "yj2PQXXC59Kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1971fd88-ab5f-431a-dde4-c0f0ca63753b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[84 31 17 15  5  9]\n",
            " [42 60 35 10  6 11]\n",
            " [16 35 62 18 12 17]\n",
            " [ 6  6 11 42 42 37]\n",
            " [ 5  3 13 45 43 64]\n",
            " [ 5  4  8 27 34 80]]\n",
            "ACCURACY SCORE:\n",
            "0.3865\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3875\n",
            "\tRecall: 0.3869\n",
            "\tF1_Score: 0.3843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "LR = LogisticRegression()\n",
        "#tfidf_vector_word = TfidfVectorizer(tokenizer=spacy_tokenizer, analyzer='word')\n",
        "tfidf_vector_char = TfidfVectorizer(tokenizer=spacy_tokenizer, analyzer='char')\n",
        "\n",
        "# Create pipeline\n",
        "pipe_LR = Pipeline([('vectorizer', tfidf_vector_char),\n",
        "                 ('classifier', LR)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_LR.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipe_LR.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "GelmU2tfhqBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b376cfd7-2c74-4d45-8ea3-850d7163a8e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "#save \n",
        "LR_accuracy = accuracy_score(y_test, y_pred)\n",
        "LR_precision = precision_score(y_test, y_pred, pos_label='positive', average='macro')\n",
        "LR_recall = recall_score(y_test, y_pred, pos_label='positive', average='macro')\n",
        "LR_f1 = f1_score(y_test, y_pred, pos_label='positive', average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOvjm_0Os7rB"
      },
      "source": [
        "### 3.3. KNN (without data cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "YibWok2EiAx7"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "TN6YYjdfs916",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc14faf0-7582-493b-f279-2ec64c3d6132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "96 fits failed out of a total of 192.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "96 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
            "    return self._fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 510, in _fit\n",
            "    \"Metric can also be a callable function.\" % (self.effective_metric_)\n",
            "ValueError: Metric 'minkowski' not valid for sparse input. Use sorted(sklearn.neighbors.VALID_METRICS_SPARSE['brute']) to get valid options. Metric can also be a callable function.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.34713542 0.34713542 0.31145833 0.31145833        nan        nan\n",
            "        nan        nan 0.35416667 0.34713542 0.340625   0.31145833\n",
            "        nan        nan        nan        nan 0.35104167 0.35286458\n",
            " 0.33723958 0.31848958        nan        nan        nan        nan\n",
            " 0.3484375  0.35755208 0.321875   0.31927083        nan        nan\n",
            "        nan        nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[78 36 30  8  5  4]\n",
            " [32 56 36  9 10 21]\n",
            " [13 24 44 24 26 29]\n",
            " [ 6  7 14 20 50 47]\n",
            " [ 3  3 15 32 49 71]\n",
            " [ 4 10 11 18 47 68]]\n",
            "ACCURACY SCORE:\n",
            "0.3281\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3340\n",
            "\tRecall: 0.3256\n",
            "\tF1_Score: 0.3255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "parameters = {'n_neighbors':np.arange(1,5), \n",
        "               'p':np.arange(1,5), \n",
        "               'weights':('uniform','distance')\n",
        "               }\n",
        "knn = KNeighborsClassifier()\n",
        "knn1 = GridSearchCV(knn, parameters, cv=6)\n",
        "pipe_knn1 = Pipeline([('vectorizer', tfidf_vector_char), \n",
        "                    ('classifier', knn1)])\n",
        "pipe_knn1.fit(X_train, y_train)\n",
        "n = knn1.best_params_['n_neighbors']\n",
        "p = knn1.best_params_['p']\n",
        "w = knn1.best_params_['weights']\n",
        "\n",
        "y_pred = pipe_knn1.predict(X_test)\n",
        "evaluate(y_test, y_pred)\n",
        "\n",
        "#save \n",
        "KNN_accuracy = accuracy_score(y_test, y_pred)\n",
        "KNN_precision = precision_score(y_test, y_pred, pos_label='positive', average='macro')\n",
        "KNN_recall = recall_score(y_test, y_pred, pos_label='positive', average='macro')\n",
        "KNN_f1 = f1_score(y_test, y_pred, pos_label='positive', average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hckBw7ertHAA"
      },
      "source": [
        "### 3.4. Decision Tree Classifier (without data cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "JYctxLH_tIo7"
      },
      "outputs": [],
      "source": [
        "# Classification\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "DTC = DecisionTreeClassifier()\n",
        "parameters = {'max_depth':np.arange(1,8)}\n",
        "DTC1 = GridSearchCV(DTC, parameters, cv=6)\n",
        "\n",
        "# Define vectorizer\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), tokenizer=spacy_tokenizer)\n",
        "\n",
        "# Create pipeline\n",
        "pipe_DTC = Pipeline([('vectorizer', tfidf_vector_char),\n",
        "                 ('classifier', DTC1)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_DTC.fit(X_train, y_train)\n",
        "d = DTC1.best_params_\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipe_DTC.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "FQw_2DTntJVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a922c15-3ba0-4c49-fa75-1c62e7840941"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[84 40 23 12  1  1]\n",
            " [40 51 53 13  3  4]\n",
            " [14 57 62 14  7  6]\n",
            " [ 6 13 25 37 53 10]\n",
            " [ 7 11 33 29 72 21]\n",
            " [11 12 19 16 57 43]]\n",
            "ACCURACY SCORE:\n",
            "0.3635\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3781\n",
            "\tRecall: 0.3609\n",
            "\tF1_Score: 0.3617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "fyHhh8vzjGVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eda522e-dcc8-422f-e034-aad0808c0b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "#save \n",
        "DTC_accuracy = accuracy_score(y_test, y_pred)\n",
        "DTC_precision = precision_score(y_test, y_pred, pos_label='positive', average='macro')\n",
        "DTC_recall = recall_score(y_test, y_pred, pos_label='positive', average='macro')\n",
        "DTC_f1 = f1_score(y_test, y_pred, pos_label='positive', average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7Dl5Oi3nUCk"
      },
      "source": [
        "### 3.5. Random Forest Classifier (without data cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "ligXOLUy59e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d0a8c5f-f264-4b34-986b-f589a1b4086a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[99 33 19  8  0  2]\n",
            " [49 63 38  7  1  6]\n",
            " [14 43 60 25  9  9]\n",
            " [ 6 10 16 51 36 25]\n",
            " [ 6  1 18 47 54 47]\n",
            " [ 5  7 13 31 35 67]]\n",
            "ACCURACY SCORE:\n",
            "0.4104\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4086\n",
            "\tRecall: 0.4107\n",
            "\tF1_Score: 0.4081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define vectorizer\n",
        "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer) # we use the above defined tokenizer\n",
        "\n",
        "# Define classifier\n",
        "RF = RandomForestClassifier()\n",
        "\n",
        "# Create pipeline\n",
        "pipe_RFC = Pipeline([('vectorizer', tfidf_vector_char),\n",
        "                 ('classifier', RF)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_RFC.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipe_RFC.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "Tge9TulgjTlC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37251b44-e770-4ab7-9d75-7e1df8e60277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "#save \n",
        "RFC_accuracy = accuracy_score(y_test, y_pred)\n",
        "RFC_precision = precision_score(y_test, y_pred, pos_label='positive', average='macro')\n",
        "RFC_recall = recall_score(y_test, y_pred, pos_label='positive', average='macro')\n",
        "RFC_f1 = f1_score(y_test, y_pred, pos_label='positive', average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9qbfnd1XLdX"
      },
      "source": [
        "### 3.6. Any other technique (with data cleaning) \n",
        "Using the algorithm with the best result, we clean the data with SpaCy NLP library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZq_oFRgDGvC"
      },
      "source": [
        "Defining our spacy_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression\n",
        "punctuations = string.punctuation\n",
        "stop_words = spacy.lang.fr.stop_words.STOP_WORDS\n",
        "def spacy_tokenizer(sentence):\n",
        "      # Create token object, which is used to create documents with linguistic annotations.\n",
        "      mytokens = sp(sentence)\n",
        "\n",
        "      # Lemmatize each token and convert each token into lowercase\n",
        "      mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
        "      ## alternative way\n",
        "      # mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "      # Remove stop words and punctuation\n",
        "      mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "      # Return preprocessed list of tokens\n",
        "      return mytokens"
      ],
      "metadata": {
        "id": "z_Lk1fRghuTG"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6L_-8piDTgZ"
      },
      "source": [
        "#### 1st try (LR with data cleaning, lemma and token)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "WAmQrOX7-sND"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('fr_core_news_sm', disable=['parser', 'ner'])"
      ],
      "metadata": {
        "id": "i_Q6H6JnybTP"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization on X_train observations\n",
        "\n",
        "def space(comment):\n",
        "    doc = nlp(comment)\n",
        "    return \" \".join([token.lemma_ for token in doc])\n",
        "X_train= X_train.apply(space)\n",
        "X_train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydutj4KwyHjb",
        "outputId": "986e1ffc-08aa-4dfc-b199-ff50ceab07d5"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70                              comment t' appelle - tu ?\n",
              "4347    voilà qui être en effet de nature à simplifier...\n",
              "1122    le pèlerin partager alors ce célébration avec ...\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR = LogisticRegression()\n",
        "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer)# Create pipeline\n",
        "pipeLR2 = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', LR)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipeLR2.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipeLR2.predict(X_test)\n",
        "evaluate(y_pred, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx1eOgTSw5WM",
        "outputId": "2e8bf191-c9ce-4185-d8e9-6101807db331"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[67 44 26 10 12  9]\n",
            " [42 54 27 11  8  4]\n",
            " [23 28 48 10 10 10]\n",
            " [11 17 20 63 34 24]\n",
            " [10 10 15 27 75 36]\n",
            " [ 8 11 24 23 34 75]]\n",
            "ACCURACY SCORE:\n",
            "0.3979\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3985\n",
            "\tRecall: 0.3959\n",
            "\tF1_Score: 0.3957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save \n",
        "LR2_accuracy = accuracy_score(y_test, y_pred)\n",
        "LR2_precision = precision_score(y_test, y_pred, pos_label='positive', average='macro')\n",
        "LR2_recall = recall_score(y_test, y_pred, pos_label='positive', average='macro')\n",
        "LR2_f1 = f1_score(y_test, y_pred, pos_label='positive', average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQl-PB0JCLg0",
        "outputId": "898e2df9-4482-4263-85c1-abf868881a77"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2nd try (LR with Doc2Vec)"
      ],
      "metadata": {
        "id": "78rjP1Dl7923"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('https://raw.githubusercontent.com/Broly-brolik/DMML2021_Tesla/main/data/unlabelled_test_data.csv')\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/Broly-brolik/DMML2021_Tesla/main/data/training_data.csv')\n",
        "sample_submission = ('https://raw.githubusercontent.com/Broly-brolik/DMML2021_Tesla/main/sample_submission.csv')"
      ],
      "metadata": {
        "id": "WDrpEVWqn9iz"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "sample_tagged = train_data.apply(lambda r: TaggedDocument(words=spacy_tokenizer(r['sentence']), tags=[r.difficulty]), axis=1)\n",
        "print(sample_tagged.head(3))"
      ],
      "metadata": {
        "id": "EVlEYe8G7_mw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d1e4936-90da-41fd-90c5-e9c1105905bf"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    ([coût, kilométrique, réel, pouvoir, diverger,...\n",
            "1        ([bleu, couleur, préférer, aime, vert], [A1])\n",
            "2    ([test, niveau, français, site, internet, écol...\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tagged.values[0]"
      ],
      "metadata": {
        "id": "bLfhs6SK8E-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69bd22e0-6777-4eab-f207-11112c039c7e"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaggedDocument(words=['coût', 'kilométrique', 'réel', 'pouvoir', 'diverger', 'sensiblement', 'valeur', 'moyen', 'fonction', 'moyen', 'transport', 'utiliser', 'taux', 'occupation', 'taux', 'remplissage', 'infrastructure', 'utiliser', 'topographie', 'ligne', 'flux', 'trafic', 'etc.'], tags=['C1'])"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split - same split as before\n",
        "train_tagged, test_tagged = train_test_split(sample_tagged, test_size=0.2, random_state=0)\n",
        "train_tagged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPsp7w858GuF",
        "outputId": "dc05dde7-1c1e-4bb9-f814-e54621d2cde4"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70                                      ([appelle], [A1])\n",
              "4347    ([nature, simplifier, sensiblement, débat, con...\n",
              "1122    ([pèlerin, partager, célébration, voisin, indi...\n",
              "4570                                 ([-ce, faite], [A1])\n",
              "34      ([obscur, devenir, maître, biosphère, devenir,...\n",
              "                              ...                        \n",
              "1033    ([micro-changement, apporter, type, union, cap...\n",
              "3264        ([aller, poste, croiser, cousin, mari], [A2])\n",
              "1653    ([cours, année, 1970, 1980, groupe, environnem...\n",
              "2607    ([figurer, vrai, père, aucun, envie, appeler],...\n",
              "2732    ([terrain, commencer, favorable, informatique,...\n",
              "Length: 3840, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_tagged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqlxP5KZ8HSZ",
        "outputId": "39ee81c6-7c10-4482-8830-7054f81e55ef"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2255    ([décembre, 1967, bien, invective, parlement, ...\n",
              "608     ([giscard, aller, pourtant, réussir, transform...\n",
              "2856    ([choix, difficile, important, public, françai...\n",
              "1889              ([débat, porte, utilité, mesure], [B1])\n",
              "1519                                 ([aller, vie], [A1])\n",
              "                              ...                        \n",
              "3553    ([engouffrer, sentier, ruer, arbre, tirer, bra...\n",
              "4595    ([prix, afficher, besoin, mettre, liste, prix,...\n",
              "891     ([présent, alimentation, antillaise, morue, in...\n",
              "1005    ([réinvente, dimanche, perspective, laïque], [...\n",
              "1940    ([femme, nuancent, régine, lemoine, darthois, ...\n",
              "Length: 960, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Allows to speed up a bit\n",
        "import multiprocessing\n",
        "cores = multiprocessing.cpu_count()"
      ],
      "metadata": {
        "id": "mQtIQc448Kqs"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Doc2Vec and build vocabulary\n",
        "from gensim.models import Doc2Vec\n",
        "\n",
        "model_dbow = Doc2Vec(dm=0, vector_size=30, negative=6, hs=0, min_count=1, sample=0, workers=cores, epoch=300)\n",
        "model_dbow.build_vocab([x for x in sample_tagged.values])"
      ],
      "metadata": {
        "id": "66xG0WFK8MTv"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train distributed Bag of Word model\n",
        "model_dbow.train(train_tagged, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)"
      ],
      "metadata": {
        "id": "VcVjhdj78OYa"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select X and y\n",
        "def vec_for_learning(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=100)) for doc in sents])\n",
        "    return targets, regressors\n",
        "\n",
        "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
      ],
      "metadata": {
        "id": "fgYAy6b08QVY"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:3]"
      ],
      "metadata": {
        "id": "O7U-AHhO8S-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "174d1b6c-c657-4163-e959-afea00bfedae"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.23166588,  0.23998977,  0.03163745, -0.17800882, -0.04882336,\n",
              "        -0.18489705, -0.24608955, -0.1396688 , -0.07768258,  0.08845659,\n",
              "        -0.20469974, -0.11909915,  0.0353523 , -0.3403728 ,  0.07838056,\n",
              "        -0.2818986 , -0.17967646,  0.17552437, -0.04133378, -0.1492834 ,\n",
              "         0.17134136, -0.18431388,  0.21888009, -0.07860448, -0.06091329,\n",
              "         0.12362346, -0.02192856, -0.15423015, -0.02916885,  0.02396392],\n",
              "       dtype=float32),\n",
              " array([-0.73345625,  0.61690694,  0.10789692, -0.3845667 , -0.24653459,\n",
              "        -0.67119104, -0.6720537 , -0.38287687, -0.3587298 ,  0.48083696,\n",
              "        -0.5635869 , -0.29771614, -0.05702979, -1.1506287 ,  0.41859108,\n",
              "        -0.94260013, -0.7198455 ,  0.4509291 , -0.2591503 , -0.57143694,\n",
              "         0.3617331 , -0.84339654,  0.6316292 , -0.39781174, -0.00738906,\n",
              "         0.36913425, -0.2482781 , -0.6240237 ,  0.07065703,  0.15128417],\n",
              "       dtype=float32),\n",
              " array([-0.94373584,  0.8321359 ,  0.12407004, -0.51239866, -0.3667969 ,\n",
              "        -0.82276785, -0.94118756, -0.4212694 , -0.450822  ,  0.5928181 ,\n",
              "        -0.7960701 , -0.44111934, -0.07210771, -1.5245488 ,  0.5223895 ,\n",
              "        -1.2292219 , -1.0004743 ,  0.5864017 , -0.3974334 , -0.7764679 ,\n",
              "         0.62265193, -1.0707616 ,  0.80942106, -0.5150178 , -0.06194269,\n",
              "         0.49667716, -0.300399  , -0.7736319 ,  0.09291209,  0.11611068],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model on training set - same algorithm as before\n",
        "LR3 = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "LR3.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = LR3.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "\n",
        "evaluate(y_test, y_pred)"
      ],
      "metadata": {
        "id": "fIluHvDM8UgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aa955d4-983a-4249-fe13-e7bddefb3591"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[102  33  20   4   2   0]\n",
            " [ 62  53  35   7   3   4]\n",
            " [ 18  26  73  22   5  16]\n",
            " [  2   6  22  58  27  29]\n",
            " [  3   3  18  37  72  40]\n",
            " [  4   2  12  29  36  75]]\n",
            "ACCURACY SCORE:\n",
            "0.4510\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4490\n",
            "\tRecall: 0.4511\n",
            "\tF1_Score: 0.4471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save \n",
        "LR3_accuracy = accuracy_score(y_test, y_pred)\n",
        "LR3_precision = precision_score(y_test, y_pred, pos_label='positive', average='macro')\n",
        "LR3_recall = recall_score(y_test, y_pred, pos_label='positive', average='macro')\n",
        "LR3_f1 = f1_score(y_test, y_pred, pos_label='positive', average='macro')"
      ],
      "metadata": {
        "id": "83noxSYzcO10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d93a170a-3e03-4692-afbe-c2d502a15428"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1365: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is our best model.\n",
        "We can now train  our model with all data from train_data and predict for test_set.\n",
        "Actually, the prediction on Kaggle was better when this model was not trained on all data but only with the train splitted set from train_data.\n",
        "So this part is not recommended to be executed."
      ],
      "metadata": {
        "id": "Yakrg1HT2p7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train the model on the whole train_data set"
      ],
      "metadata": {
        "id": "8kKAdDDbE_Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Doc2Vec and build vocabulary\n",
        "from gensim.models import Doc2Vec\n",
        "\n",
        "# model_dbow = Doc2Vec(dm=0, vector_size=30, negative=6, hs=0, min_count=1, sample=0, workers=cores, epoch=300)\n",
        "# model_dbow.build_vocab([x for x in sample_tagged.values])\n",
        "# model_dbow.train(sample_tagged, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs) # train on sample_tagged, i.e. all the set"
      ],
      "metadata": {
        "id": "iU65zdeU2uO8"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tagged_test = test_data.apply(lambda r: TaggedDocument(words=spacy_tokenizer(r[\"sentence\"]), tags=r[\"id\"]), axis=1)"
      ],
      "metadata": {
        "id": "5z5iVto6ppBX"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the X_test, which is our sentences from test_data\n",
        "sents = sample_tagged_test.values\n",
        "X_test = np.asarray([model_dbow.infer_vector(doc.words, steps=100) for doc in sents])"
      ],
      "metadata": {
        "id": "0TE9XBt8qXIB"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lO_qhkUsnbS",
        "outputId": "245dc6bc-49a0-42db-8c2d-caacf488a242"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = LR3.predict(X_test)"
      ],
      "metadata": {
        "id": "rMaDe52bs1bh"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_tagged"
      ],
      "metadata": {
        "id": "DsVfC5GetZwR"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bonus"
      ],
      "metadata": {
        "id": "sYmRRwB28bmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some functions to clean the data (but was done by space_tokenizer)"
      ],
      "metadata": {
        "id": "wGb8M1PK9Amf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All in lower case\n",
        "# X_train = X_train.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "# Remove duplicates\n",
        "# X_train = X_train.drop_duplicates\n",
        "# Removing stopwords on X_train observations\n",
        "# X_train = X_train.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "# Removing punctuations on X_train observations\n",
        "# X_train = X_train.str.replace('[^\\w\\s]','')"
      ],
      "metadata": {
        "id": "ExbVhUwI8dr0"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADvuWSdwXnOW"
      },
      "source": [
        "## 4. Summary of the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "Kvw2PVDqYUWY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "02b1f2a6-abd5-46e8-bbbd-14aee22333ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3c3e8796-82d8-43e2-aef9-27d794e5af4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.386458</td>\n",
              "      <td>0.387544</td>\n",
              "      <td>0.386941</td>\n",
              "      <td>0.384255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.328125</td>\n",
              "      <td>0.334029</td>\n",
              "      <td>0.325574</td>\n",
              "      <td>0.325542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.363542</td>\n",
              "      <td>0.378131</td>\n",
              "      <td>0.360916</td>\n",
              "      <td>0.361749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.410417</td>\n",
              "      <td>0.408577</td>\n",
              "      <td>0.410735</td>\n",
              "      <td>0.408088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LR2</td>\n",
              "      <td>0.397917</td>\n",
              "      <td>0.395941</td>\n",
              "      <td>0.398521</td>\n",
              "      <td>0.395732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LR3</td>\n",
              "      <td>0.451042</td>\n",
              "      <td>0.448963</td>\n",
              "      <td>0.451101</td>\n",
              "      <td>0.447058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c3e8796-82d8-43e2-aef9-27d794e5af4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c3e8796-82d8-43e2-aef9-27d794e5af4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c3e8796-82d8-43e2-aef9-27d794e5af4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                       Name  Accuracy  Precision    Recall        f1\n",
              "0       Logistic Regression  0.386458   0.387544  0.386941  0.384255\n",
              "1                       KNN  0.328125   0.334029  0.325574  0.325542\n",
              "2  Decision Tree Classifier  0.363542   0.378131  0.360916  0.361749\n",
              "3  Random Forest Classifier  0.410417   0.408577  0.410735  0.408088\n",
              "4                       LR2  0.397917   0.395941  0.398521  0.395732\n",
              "5                       LR3  0.451042   0.448963  0.451101  0.447058"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ],
      "source": [
        " # make a frame with the summaries\n",
        "summarises = pd.DataFrame({'Name': ['Logistic Regression', 'KNN', 'Decision Tree Classifier', 'Random Forest Classifier', 'LR2', 'LR3'],\n",
        "                          'Accuracy': [LR_accuracy, KNN_accuracy, DTC_accuracy, RFC_accuracy, LR2_accuracy, LR3_accuracy],\n",
        "                          'Precision': [LR_precision, KNN_precision, DTC_precision, RFC_precision, LR2_precision, LR3_precision],\n",
        "                          'Recall': [LR_recall, KNN_recall, DTC_recall, RFC_recall, LR2_recall, LR3_recall],\n",
        "                          'f1': [LR_f1, KNN_f1, DTC_f1, RFC_f1, LR2_f1, LR3_f1]\n",
        "                          })\n",
        "\n",
        "\n",
        "summarises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0qxwTNQtXt8"
      },
      "source": [
        "## 5. Predict test set with our best model, and export it in a .csv file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1. Predict "
      ],
      "metadata": {
        "id": "pNA8Xc3uW_eh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "pBCGs8sTtfcB"
      },
      "outputs": [],
      "source": [
        "# Fit it with our best model (e.g. pipeLR, pipeknn, pipeDTC, etc.)\n",
        "# pipeX.fit(X, y) # we can now train it on the whole train set\n",
        "# test_pred = pipeX.predict(test_data['sentence'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in our case the best model was LR3, and we did not want to train the model on all the set, we can just  go the section where there is the model, run it in order to have the test_pred variable filled."
      ],
      "metadata": {
        "id": "EwvYXpkXGsQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2. Create the dataframe, convert it and download it."
      ],
      "metadata": {
        "id": "BTRmOjh6XvEZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "e0sAPw7_2d7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a41a6c63-aa8c-46f2-9385-1bf8f33b142f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-91a60595-d859-4b54-a096-7e011fdd5bd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>B1</td>\n",
              "      <td>1195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>A2</td>\n",
              "      <td>1196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>C2</td>\n",
              "      <td>1197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>B2</td>\n",
              "      <td>1198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>C2</td>\n",
              "      <td>1199</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91a60595-d859-4b54-a096-7e011fdd5bd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91a60595-d859-4b54-a096-7e011fdd5bd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91a60595-d859-4b54-a096-7e011fdd5bd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     difficulty    id\n",
              "0            C1     0\n",
              "1            B1     1\n",
              "2            A2     2\n",
              "3            B2     3\n",
              "4            C2     4\n",
              "...         ...   ...\n",
              "1195         B1  1195\n",
              "1196         A2  1196\n",
              "1197         C2  1197\n",
              "1198         B2  1198\n",
              "1199         C2  1199\n",
              "\n",
              "[1200 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "# create the dataframe as asked\n",
        "submission = pd.DataFrame(data=test_pred, columns=['difficulty']) #creating the dataframe with the prediction values.\n",
        "submission['id'] = submission.index #adding the column 'id'\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "qzlcFSSC9xUG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2d354a6a-c767-44ad-d142-2f76e1a70483"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_01b6c4ee-f610-487b-94ae-b1e75ac0f06c\", \"submission.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#export the dataframe as a .csv file\n",
        "submission.to_csv('submission.csv', index=False) #deleting the index column\n",
        "from google.colab import files\n",
        "files.download('submission.csv') # downloading the .csv file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "30VFiZh6aJu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We submitted the prediction with LR3 model."
      ],
      "metadata": {
        "id": "a6tyPDSdaPJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Youtube video"
      ],
      "metadata": {
        "id": "Fk5EVPN1aL4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%HTML\n",
        "<iframe width=\"560\" src=\"https://youtube.com/embed/zIJN3GRUI3s\"></iframe>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "oGM--6LJaNPJ",
        "outputId": "568c9b88-4f59-4927-bd50-35e00df00fea"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<iframe width=\"560\" src=\"https://youtube.com/embed/zIJN3GRUI3s\"></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have issues for watching the video here, you can directly go to this link: https://youtu.be/zIJN3GRUI3s"
      ],
      "metadata": {
        "id": "CFeH0aO8fVq5"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DMML2021_TESLA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}